{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNkzVb8IfkozoLZUaSSlvgh","include_colab_link":true},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rupify/cifar10-pytorch?scriptVersionId=260157087\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Rupkatha-dev/Task1-IIT-G-/blob/main/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"Import Libraries","metadata":{"id":"AMwhsR7j6ED7"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"id":"1iGYmJMn54ZT","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:26:37.597653Z","iopub.execute_input":"2025-09-04T06:26:37.598267Z","iopub.status.idle":"2025-09-04T06:26:43.520437Z","shell.execute_reply.started":"2025-09-04T06:26:37.598243Z","shell.execute_reply":"2025-09-04T06:26:43.519869Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load and Preprocess the CIFAR-10 Dataset","metadata":{"id":"NqakGFh46YzR"}},{"cell_type":"code","source":"# Transform: Convert to Tensor and Normalize\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"id":"7TgL3nLl6Z0f","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:26:43.521454Z","iopub.execute_input":"2025-09-04T06:26:43.52179Z","iopub.status.idle":"2025-09-04T06:26:43.525663Z","shell.execute_reply.started":"2025-09-04T06:26:43.521761Z","shell.execute_reply":"2025-09-04T06:26:43.524963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training set\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n                                          shuffle=True, num_workers=2)\n# Test set\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64,\n                                         shuffle=False, num_workers=2)\n","metadata":{"id":"PYjb7mLA6hIZ","outputId":"120e4fc0-24c3-4b7e-c932-722ffd3ea934","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:26:43.526368Z","iopub.execute_input":"2025-09-04T06:26:43.526648Z","iopub.status.idle":"2025-09-04T06:26:50.692772Z","shell.execute_reply.started":"2025-09-04T06:26:43.526627Z","shell.execute_reply":"2025-09-04T06:26:50.692231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CIFAR-10 Classes\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"id":"ah_HIYoC6lAY","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:26:50.69367Z","iopub.execute_input":"2025-09-04T06:26:50.693856Z","iopub.status.idle":"2025-09-04T06:26:50.6971Z","shell.execute_reply.started":"2025-09-04T06:26:50.693841Z","shell.execute_reply":"2025-09-04T06:26:50.69653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the CNN Model","metadata":{"id":"o6E5s2Vz6thA"}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # Convolutional Layers\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)   \n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)          \n\n        # Fully Connected Layers\n        self.fc1 = nn.Linear(64 * 8 * 8, 512)         \n        self.fc2 = nn.Linear(512, 10)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))   \n        x = self.pool(self.relu(self.conv2(x)))   \n        x = x.view(-1, 64 * 8 * 8)                \n        x = self.dropout(self.relu(self.fc1(x)))  \n        x = self.fc2(x)                          \n        return x\n\n# Instantiate Model\nnet = CNN()\n\n# Select device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nnet = net.to(device)","metadata":{"id":"MxmvwRhz6p_T","outputId":"10a6afec-397a-48ea-f482-0c6020052817","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:26:50.699057Z","iopub.execute_input":"2025-09-04T06:26:50.699242Z","iopub.status.idle":"2025-09-04T06:26:51.026083Z","shell.execute_reply.started":"2025-09-04T06:26:50.699227Z","shell.execute_reply":"2025-09-04T06:26:51.02528Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define Loss Function and Optimizer","metadata":{"id":"QrFyzE7V80kV"}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()        \noptimizer = optim.Adam(net.parameters(), lr=0.001)\n","metadata":{"id":"zv2JVN0R81Vo","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:26:51.027017Z","iopub.execute_input":"2025-09-04T06:26:51.027314Z","iopub.status.idle":"2025-09-04T06:26:51.031409Z","shell.execute_reply.started":"2025-09-04T06:26:51.027297Z","shell.execute_reply":"2025-09-04T06:26:51.030895Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the CNN","metadata":{"id":"VGHeJRrd84qx"}},{"cell_type":"code","source":"epochs = 5  \n\nfor epoch in range(epochs):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n       \n        optimizer.zero_grad()\n\n        # Forward + Backward + Optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n\nprint(\"Training finshed\")\n","metadata":{"id":"c4nEpbP585pU","outputId":"4fff0ba4-c2a3-42f1-853b-8fc5b47bbcbc","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:28:14.657563Z","iopub.execute_input":"2025-09-04T06:28:14.658113Z","iopub.status.idle":"2025-09-04T06:29:00.787073Z","shell.execute_reply.started":"2025-09-04T06:28:14.658082Z","shell.execute_reply":"2025-09-04T06:29:00.78633Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Test the Model","metadata":{"id":"8AS8llUO9NrI"}},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device) \n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)  \n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Accuracy: {100 * correct / total:.2f}%\")\n","metadata":{"id":"Aap7K4p39O7R","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:29:03.457496Z","iopub.execute_input":"2025-09-04T06:29:03.457766Z","iopub.status.idle":"2025-09-04T06:29:05.151177Z","shell.execute_reply.started":"2025-09-04T06:29:03.457747Z","shell.execute_reply":"2025-09-04T06:29:05.150485Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Predict on Sample Images","metadata":{"id":"B9xkTlG-9SzY"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef imshow(img):\n    img = img / 2 + 0.5 \n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# random test images\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n\n# Show images\nimshow(torchvision.utils.make_grid(images[:7]))\nprint('GroundTruth: ', ' '.join(f'{classes[labels[j]]}' for j in range(7)))\n\noutputs = net(images[:7].to(device))\n\n#predicted labels\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted:   ', ' '.join(f'{classes[predicted[j].item()]}' for j in range(7)))\n","metadata":{"id":"0PfVgS3U9XhA","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:29:41.173248Z","iopub.execute_input":"2025-09-04T06:29:41.173607Z","iopub.status.idle":"2025-09-04T06:29:41.500394Z","shell.execute_reply.started":"2025-09-04T06:29:41.173578Z","shell.execute_reply":"2025-09-04T06:29:41.499492Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define AlexNet Model","metadata":{"id":"QoRCs5s_HrgE"}},{"cell_type":"code","source":"class alexNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(alexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 4 * 4, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(1024, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\nalexnet= alexNet(num_classes=10)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nalexnet = alexnet.to(device)\n","metadata":{"id":"Tt8M6QQ1Hszu","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:29:47.264955Z","iopub.execute_input":"2025-09-04T06:29:47.265249Z","iopub.status.idle":"2025-09-04T06:29:47.327206Z","shell.execute_reply.started":"2025-09-04T06:29:47.265222Z","shell.execute_reply":"2025-09-04T06:29:47.326495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define Loss Function and Optimize","metadata":{"id":"fy2A_CpYH5BF"}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(alexnet.parameters(), lr=0.001)\n","metadata":{"id":"78k1cwfHH52h","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:30:01.857825Z","iopub.execute_input":"2025-09-04T06:30:01.858093Z","iopub.status.idle":"2025-09-04T06:30:01.862233Z","shell.execute_reply.started":"2025-09-04T06:30:01.858064Z","shell.execute_reply":"2025-09-04T06:30:01.861628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train AlexNet","metadata":{"id":"EtpSBl_sIJxG"}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(alexnet.parameters(), lr=0.001)\n\nepochs = 5 \nfor epoch in range(epochs):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n        optimizer.zero_grad()\n        outputs = alexnet(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n\nprint(\"Training Finished ✅\")\n","metadata":{"id":"1BUh9RBMH-F-","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:30:05.182639Z","iopub.execute_input":"2025-09-04T06:30:05.182931Z","iopub.status.idle":"2025-09-04T06:30:59.977129Z","shell.execute_reply.started":"2025-09-04T06:30:05.182909Z","shell.execute_reply":"2025-09-04T06:30:59.976258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Test Accuracy","metadata":{"id":"hhcqOqALIu_-"}},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = alexnet(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Accuracy on 10000 test images: {100 * correct / total:.2f}%\")\n","metadata":{"id":"HUU4psHZIwG0","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:31:01.943536Z","iopub.execute_input":"2025-09-04T06:31:01.944431Z","iopub.status.idle":"2025-09-04T06:31:03.966255Z","shell.execute_reply.started":"2025-09-04T06:31:01.944394Z","shell.execute_reply":"2025-09-04T06:31:03.965203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Prediction on Sample Images","metadata":{"id":"vcplhrspJA5u"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n\n\nimshow(torchvision.utils.make_grid(images[:7]))\n\nprint('GroundTruth: ', ' '.join(f'{classes[labels[j]]}' for j in range(7)))\n\n\noutputs = alexnet(images[:7].to(device))\n\n\n_, predicted = torch.max(outputs, 1)\n\n\nprint('Predicted:   ', ' '.join(f'{classes[predicted[j].item()]}' for j in range(7)))\n","metadata":{"id":"pMVoB8GUI_QL","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T06:31:08.258272Z","iopub.execute_input":"2025-09-04T06:31:08.258616Z","iopub.status.idle":"2025-09-04T06:31:08.52032Z","shell.execute_reply.started":"2025-09-04T06:31:08.258588Z","shell.execute_reply":"2025-09-04T06:31:08.519017Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Pre-Trained ResNet","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision import models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T12:59:25.818199Z","iopub.execute_input":"2025-09-05T12:59:25.818456Z","iopub.status.idle":"2025-09-05T12:59:35.294694Z","shell.execute_reply.started":"2025-09-05T12:59:25.818435Z","shell.execute_reply":"2025-09-05T12:59:35.293943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:00:19.865981Z","iopub.execute_input":"2025-09-05T13:00:19.866604Z","iopub.status.idle":"2025-09-05T13:00:19.957168Z","shell.execute_reply.started":"2025-09-05T13:00:19.866577Z","shell.execute_reply":"2025-09-05T13:00:19.956355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Preparation","metadata":{}},{"cell_type":"code","source":"# Resize to 224x224 for ResNet\ntransform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T12:59:41.193951Z","iopub.execute_input":"2025-09-05T12:59:41.194211Z","iopub.status.idle":"2025-09-05T12:59:41.198364Z","shell.execute_reply.started":"2025-09-05T12:59:41.19419Z","shell.execute_reply":"2025-09-05T12:59:41.197498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 64\n\n# Train dataset\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\n# Test dataset\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T12:59:44.836026Z","iopub.execute_input":"2025-09-05T12:59:44.836565Z","iopub.status.idle":"2025-09-05T12:59:50.258363Z","shell.execute_reply.started":"2025-09-05T12:59:44.836535Z","shell.execute_reply":"2025-09-05T12:59:50.257632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T12:59:53.723296Z","iopub.execute_input":"2025-09-05T12:59:53.723586Z","iopub.status.idle":"2025-09-05T12:59:53.727039Z","shell.execute_reply.started":"2025-09-05T12:59:53.723561Z","shell.execute_reply":"2025-09-05T12:59:53.726524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load Pre-trained ResNet","metadata":{}},{"cell_type":"code","source":"resnet = models.resnet18(pretrained=True)\n\n\nnum_ftrs = resnet.fc.in_features\nresnet.fc = nn.Linear(num_ftrs, 10)\n\nresnet = resnet.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:00:27.105603Z","iopub.execute_input":"2025-09-05T13:00:27.106103Z","iopub.status.idle":"2025-09-05T13:00:27.497302Z","shell.execute_reply.started":"2025-09-05T13:00:27.106077Z","shell.execute_reply":"2025-09-05T13:00:27.496765Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define Loss Function and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(resnet.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:00:34.25775Z","iopub.execute_input":"2025-09-05T13:00:34.257997Z","iopub.status.idle":"2025-09-05T13:00:34.262082Z","shell.execute_reply.started":"2025-09-05T13:00:34.25798Z","shell.execute_reply":"2025-09-05T13:00:34.261524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the Model","metadata":{}},{"cell_type":"code","source":"EPOCHS = 5\n\nfor epoch in range(EPOCHS):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n        outputs = resnet(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # Print once per epoch\n    avg_loss = running_loss / len(trainloader)\n    print(f\"[{epoch+1}] loss: {avg_loss:.3f}\")\n\nprint(\"Finished Training ✅\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:04:25.779115Z","iopub.execute_input":"2025-09-05T13:04:25.779415Z","iopub.status.idle":"2025-09-05T13:18:05.052616Z","shell.execute_reply.started":"2025-09-05T13:04:25.77939Z","shell.execute_reply":"2025-09-05T13:18:05.051831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PATH = './resnet_cifar10.pth'\ntorch.save(resnet.state_dict(), PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:18:54.749801Z","iopub.execute_input":"2025-09-05T13:18:54.750106Z","iopub.status.idle":"2025-09-05T13:18:54.832092Z","shell.execute_reply.started":"2025-09-05T13:18:54.750074Z","shell.execute_reply":"2025-09-05T13:18:54.831519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = resnet(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Accuracy on 10000 test images: {100 * correct / total:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:19:01.672018Z","iopub.execute_input":"2025-09-05T13:19:01.672833Z","iopub.status.idle":"2025-09-05T13:19:14.585649Z","shell.execute_reply.started":"2025-09-05T13:19:01.672806Z","shell.execute_reply":"2025-09-05T13:19:14.584889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.cpu().numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get some random test images\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n\n# Show images (keep on CPU for matplotlib)\nimshow(torchvision.utils.make_grid(images[:7]))\nprint('GroundTruth: ', ' '.join(f'{classes[labels[j]]}' for j in range(17)))\n\n# Move images to GPU for prediction\noutputs = resnet(images[:17].to(device))\n_, predicted = torch.max(outputs, 1)\n\n# Print predicted labels\nprint('Predicted:   ', ' '.join(f'{classes[predicted[j].item()]}' for j in range(17)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:19:36.471301Z","iopub.execute_input":"2025-09-05T13:19:36.47241Z","iopub.status.idle":"2025-09-05T13:19:37.004604Z","shell.execute_reply.started":"2025-09-05T13:19:36.472369Z","shell.execute_reply":"2025-09-05T13:19:37.003771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Inception","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:47:43.997832Z","iopub.execute_input":"2025-09-05T13:47:43.998067Z","iopub.status.idle":"2025-09-05T13:47:54.20358Z","shell.execute_reply.started":"2025-09-05T13:47:43.998049Z","shell.execute_reply":"2025-09-05T13:47:54.202954Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Transformations for CIFAR-10\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),   # ✅ Inception needs 299x299\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Load train and test datasets\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n\nclasses = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:47:54.204551Z","iopub.execute_input":"2025-09-05T13:47:54.204855Z","iopub.status.idle":"2025-09-05T13:48:00.453274Z","shell.execute_reply.started":"2025-09-05T13:47:54.204828Z","shell.execute_reply":"2025-09-05T13:48:00.452167Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 59.0MB/s] \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:48:00.454812Z","iopub.execute_input":"2025-09-05T13:48:00.455114Z","iopub.status.idle":"2025-09-05T13:48:00.543897Z","shell.execute_reply.started":"2025-09-05T13:48:00.455083Z","shell.execute_reply":"2025-09-05T13:48:00.543158Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torchvision.models as models\n\ninception = models.inception_v3(pretrained=True)\n\n# Replace final fully connected layer\ninception.fc = nn.Linear(inception.fc.in_features, 10)\n\ninception = inception.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(inception.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:48:03.597058Z","iopub.execute_input":"2025-09-05T13:48:03.597324Z","iopub.status.idle":"2025-09-05T13:48:04.978301Z","shell.execute_reply.started":"2025-09-05T13:48:03.597303Z","shell.execute_reply":"2025-09-05T13:48:04.97751Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n100%|██████████| 104M/104M [00:00<00:00, 171MB/s]  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"EPOCHS = 2   # keep small for demo\n\nfor epoch in range(EPOCHS):\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n        outputs = inception(inputs)\n        if isinstance(outputs, tuple):   # Inception gives (main, aux)\n            outputs = outputs[0]\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_loss = running_loss / len(trainloader)\n    print(f\"[{epoch+1}] loss: {avg_loss:.3f}\")\n\nprint(\"Finished Training ✅\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T13:48:11.01328Z","iopub.execute_input":"2025-09-05T13:48:11.013985Z","iopub.status.idle":"2025-09-05T14:14:49.773804Z","shell.execute_reply.started":"2025-09-05T13:48:11.013962Z","shell.execute_reply":"2025-09-05T14:14:49.773155Z"}},"outputs":[{"name":"stdout","text":"[1] loss: 0.780\n[2] loss: 0.454\nFinished Training ✅\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = inception(images)\n        if isinstance(outputs, tuple):\n            outputs = outputs[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Accuracy on 10000 test images: {100 * correct / total:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get random test images\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n\n# Show images\nimshow(torchvision.utils.make_grid(images[:4]))\nprint('GroundTruth:', ' '.join(f'{classes[labels[j]]}' for j in range(4)))\n\n# Predict\noutputs = inception(images[:4].to(device))\nif isinstance(outputs, tuple):\n    outputs = outputs[0]\n_, predicted = torch.max(outputs, 1)\nprint('Predicted:  ', ' '.join(f'{classes[predicted[j]]}' for j in range(4)))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}