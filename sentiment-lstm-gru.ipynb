{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:03:35.300506Z","iopub.execute_input":"2025-10-06T06:03:35.301281Z","iopub.status.idle":"2025-10-06T06:03:43.968106Z","shell.execute_reply.started":"2025-10-06T06:03:35.301253Z","shell.execute_reply":"2025-10-06T06:03:43.967569Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:03:51.234339Z","iopub.execute_input":"2025-10-06T06:03:51.234848Z","iopub.status.idle":"2025-10-06T06:03:51.324258Z","shell.execute_reply.started":"2025-10-06T06:03:51.234811Z","shell.execute_reply":"2025-10-06T06:03:51.323603Z"}},"outputs":[{"name":"stdout","text":"Using: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:03:54.364064Z","iopub.execute_input":"2025-10-06T06:03:54.364335Z","iopub.status.idle":"2025-10-06T06:03:56.079814Z","shell.execute_reply.started":"2025-10-06T06:03:54.364316Z","shell.execute_reply":"2025-10-06T06:03:56.079063Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:03:58.445002Z","iopub.execute_input":"2025-10-06T06:03:58.445699Z","iopub.status.idle":"2025-10-06T06:03:58.467205Z","shell.execute_reply.started":"2025-10-06T06:03:58.445674Z","shell.execute_reply":"2025-10-06T06:03:58.466398Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"stop_words = set(stopwords.words(\"english\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:02.929452Z","iopub.execute_input":"2025-10-06T06:04:02.930063Z","iopub.status.idle":"2025-10-06T06:04:02.933960Z","shell.execute_reply.started":"2025-10-06T06:04:02.930037Z","shell.execute_reply":"2025-10-06T06:04:02.933302Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"<br />\", \" \", text)\n    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n    words = text.split()\n    words = [w for w in words if w not in stop_words]\n    return words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:05.253510Z","iopub.execute_input":"2025-10-06T06:04:05.253817Z","iopub.status.idle":"2025-10-06T06:04:05.258314Z","shell.execute_reply.started":"2025-10-06T06:04:05.253798Z","shell.execute_reply":"2025-10-06T06:04:05.257449Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df['tokens'] = df['review'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:07.421179Z","iopub.execute_input":"2025-10-06T06:04:07.421791Z","iopub.status.idle":"2025-10-06T06:04:12.917548Z","shell.execute_reply.started":"2025-10-06T06:04:07.421767Z","shell.execute_reply":"2025-10-06T06:04:12.916961Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"all_words = [word for tokens in df['tokens'] for word in tokens]\nword_counts = Counter(all_words)\nvocab = sorted(word_counts, key=word_counts.get, reverse=True)\nvocab_to_int = {word: idx+1 for idx, word in enumerate(vocab)} ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:19.426764Z","iopub.execute_input":"2025-10-06T06:04:19.427033Z","iopub.status.idle":"2025-10-06T06:04:20.338045Z","shell.execute_reply.started":"2025-10-06T06:04:19.427013Z","shell.execute_reply":"2025-10-06T06:04:20.337234Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def encode_tokens(tokens):\n    return [vocab_to_int.get(word, 0) for word in tokens]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:27.347258Z","iopub.execute_input":"2025-10-06T06:04:27.347561Z","iopub.status.idle":"2025-10-06T06:04:27.351789Z","shell.execute_reply.started":"2025-10-06T06:04:27.347509Z","shell.execute_reply":"2025-10-06T06:04:27.350990Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df['encoded'] = df['tokens'].apply(encode_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:29.667094Z","iopub.execute_input":"2025-10-06T06:04:29.667373Z","iopub.status.idle":"2025-10-06T06:04:30.618050Z","shell.execute_reply.started":"2025-10-06T06:04:29.667353Z","shell.execute_reply":"2025-10-06T06:04:30.617442Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"max_len = 200\n\ndef pad_sequence(seq, max_len):\n    return seq[:max_len] + [0]*(max_len-len(seq))\n\nfeatures = np.array([pad_sequence(seq, max_len) for seq in df['encoded']])\nlabels = np.array(df['sentiment'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:33.504946Z","iopub.execute_input":"2025-10-06T06:04:33.505215Z","iopub.status.idle":"2025-10-06T06:04:34.864060Z","shell.execute_reply.started":"2025-10-06T06:04:33.505193Z","shell.execute_reply":"2025-10-06T06:04:34.863250Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\ntrain_data = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float))\ntest_data = TensorDataset(torch.tensor(X_test, dtype=torch.long), torch.tensor(y_test, dtype=torch.float))\n\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=64)\ntest_loader = DataLoader(test_data, shuffle=False, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:04:37.332413Z","iopub.execute_input":"2025-10-06T06:04:37.332915Z","iopub.status.idle":"2025-10-06T06:04:37.451481Z","shell.execute_reply.started":"2025-10-06T06:04:37.332891Z","shell.execute_reply":"2025-10-06T06:04:37.450916Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class LSTM_GRU_Model(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers=1, dropout=0.3):\n        super(LSTM_GRU_Model, self).__init__()\n        self.embedding = nn.Embedding(vocab_size+1, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=n_layers, \n                            batch_first=True, dropout=dropout)\n        self.gru = nn.GRU(hidden_dim, hidden_dim, num_layers=n_layers, \n                          batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_dim, 1)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        lstm_out, _ = self.lstm(x)\n        gru_out, _ = self.gru(lstm_out)\n        out = gru_out[:, -1, :]   # take last hidden state\n        out = self.dropout(out)\n        out = self.fc(out)        # raw logits\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:17:11.188974Z","iopub.execute_input":"2025-10-06T06:17:11.189452Z","iopub.status.idle":"2025-10-06T06:17:11.194892Z","shell.execute_reply.started":"2025-10-06T06:17:11.189429Z","shell.execute_reply":"2025-10-06T06:17:11.194276Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# GPU setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# vocab_to_int is a dict: word -> index\nmax_idx = max(vocab_to_int.values())\n\n# Parameters\nembed_dim = 128\nhidden_dim = 128\noutput_dim = 2   # Positive, Neutral, Negative\n\n# Create model\nmodel = LSTM_GRU_Model(vocab_size=max_idx+1, embed_dim=embed_dim, \n                       hidden_dim=hidden_dim, output_dim=1).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:17:14.599745Z","iopub.execute_input":"2025-10-06T06:17:14.600008Z","iopub.status.idle":"2025-10-06T06:17:14.764694Z","shell.execute_reply.started":"2025-10-06T06:17:14.599989Z","shell.execute_reply":"2025-10-06T06:17:14.763901Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn as nn\n\n# ✅ Loss function for binary sentiment classification\ncriterion = nn.BCEWithLogitsLoss()\n\n# ✅ Optimizer (Adam works well for NLP tasks)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:17:39.042903Z","iopub.execute_input":"2025-10-06T06:17:39.043163Z","iopub.status.idle":"2025-10-06T06:17:39.047236Z","shell.execute_reply.started":"2025-10-06T06:17:39.043144Z","shell.execute_reply":"2025-10-06T06:17:39.046694Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"epochs = 3\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0.0\n    \n    for inputs, targets in tqdm(train_loader):\n        inputs, targets = inputs.to(device), targets.to(device).float()  # BCE expects float targets\n        \n        optimizer.zero_grad()\n        output = model(inputs).squeeze()   # shape: [batch_size]\n        loss = criterion(output, targets)\n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:17:54.158760Z","iopub.execute_input":"2025-10-06T06:17:54.159029Z","iopub.status.idle":"2025-10-06T06:18:22.069574Z","shell.execute_reply.started":"2025-10-06T06:17:54.159008Z","shell.execute_reply":"2025-10-06T06:18:22.068727Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 625/625 [00:10<00:00, 61.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3, Loss: 0.6928\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 625/625 [00:08<00:00, 71.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3, Loss: 0.6422\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 625/625 [00:08<00:00, 69.95it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3, Loss: 0.4786\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"model.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for inputs, targets in test_loader:\n        inputs, targets = inputs.to(device), targets.to(device).float()\n        outputs = model(inputs).squeeze()\n        preds = torch.sigmoid(outputs) > 0.5\n        correct += (preds == targets.bool()).sum().item()\n        total += targets.size(0)\n\nprint(f\"Accuracy: {correct / total * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:18:34.868285Z","iopub.execute_input":"2025-10-06T06:18:34.868604Z","iopub.status.idle":"2025-10-06T06:18:35.751519Z","shell.execute_reply.started":"2025-10-06T06:18:34.868580Z","shell.execute_reply":"2025-10-06T06:18:35.750907Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 83.64%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nall_preds = []\nall_targets = []\n\nmodel.eval()\nwith torch.no_grad():\n    for inputs, targets in test_loader:\n        inputs, targets = inputs.to(device), targets.to(device).float()\n        outputs = model(inputs).squeeze()\n        preds = (torch.sigmoid(outputs) > 0.5).int()\n        all_preds.extend(preds.cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n\nprint(classification_report(all_targets, all_preds, target_names=['Negative', 'Positive']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:19:59.074098Z","iopub.execute_input":"2025-10-06T06:19:59.074383Z","iopub.status.idle":"2025-10-06T06:19:59.841488Z","shell.execute_reply.started":"2025-10-06T06:19:59.074362Z","shell.execute_reply":"2025-10-06T06:19:59.840843Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    Negative       0.87      0.79      0.83      4961\n    Positive       0.81      0.88      0.84      5039\n\n    accuracy                           0.84     10000\n   macro avg       0.84      0.84      0.84     10000\nweighted avg       0.84      0.84      0.84     10000\n\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"Custom review","metadata":{}},{"cell_type":"code","source":"def preprocess_review(review, word2idx, max_len):\n    # 1. Lowercase and simple split (you can add more preprocessing)\n    tokens = review.lower().split()\n    \n    # 2. Convert to indices (unknown words get index 0)\n    indices = [word2idx.get(token, 0) for token in tokens]\n    \n    # 3. Pad / truncate to max_len\n    if len(indices) < max_len:\n        indices += [0] * (max_len - len(indices))\n    else:\n        indices = indices[:max_len]\n    \n    return torch.tensor(indices).unsqueeze(0)  # shape: [1, max_len]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:20:56.679911Z","iopub.execute_input":"2025-10-06T06:20:56.680452Z","iopub.status.idle":"2025-10-06T06:20:56.684959Z","shell.execute_reply.started":"2025-10-06T06:20:56.680428Z","shell.execute_reply":"2025-10-06T06:20:56.684319Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"torch.save(model.state_dict(), \"sentiment_model.pth\")\nprint(\"Model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:23:42.442886Z","iopub.execute_input":"2025-10-06T06:23:42.443641Z","iopub.status.idle":"2025-10-06T06:23:42.556831Z","shell.execute_reply.started":"2025-10-06T06:23:42.443617Z","shell.execute_reply":"2025-10-06T06:23:42.556208Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# Load model (replace class definition if needed)\nmodel = LSTM_GRU_Model(vocab_size=len(word2idx)+1, embed_dim=100, hidden_dim=128, output_dim=1).to(device)\nmodel.load_state_dict(torch.load(\"sentiment_model.pth\"))\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T06:24:20.225808Z","iopub.execute_input":"2025-10-06T06:24:20.226489Z","iopub.status.idle":"2025-10-06T06:24:20.240954Z","shell.execute_reply.started":"2025-10-06T06:24:20.226468Z","shell.execute_reply":"2025-10-06T06:24:20.240185Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1384688894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load model (replace class definition if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_GRU_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'word2idx' is not defined"],"ename":"NameError","evalue":"name 'word2idx' is not defined","output_type":"error"}],"execution_count":51}]}